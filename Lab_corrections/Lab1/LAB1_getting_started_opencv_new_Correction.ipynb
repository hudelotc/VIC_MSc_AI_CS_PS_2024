{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FVa1eUrFyEoz"
   },
   "source": [
    "<center><img src='./Figs/cs-logo.png' width=200></center>\n",
    "\n",
    "<h6><center></center></h6>\n",
    "\n",
    "<h1>\n",
    "<hr style=\"border:none; height:3px;\">\n",
    "<center>Lab 1: Getting Started with OpenCV - Color Representation Spaces</center>\n",
    "<hr style=\"border:none; height:3px;\">\n",
    "</h1>\n",
    "\n",
    "## Foreword\n",
    "The practical sessions for the Computer Vision course will be conducted using the [OpenCV](http://opencv.org/) library as well as the [scikit image](https://scikit-image.org/) one in the environment of your choice, and they will involve applications of various concepts covered in the lectures.  \n",
    "OpenCV provides interfaces in C++, C, Python, and Java, allowing you to use the one that best suits your needs, with a preference for the Python interface. These notebooks use the Python interface, and the solutions will be provided in Python.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nf3uiA_yyEo2"
   },
   "source": [
    "## Exercise 1: OpenCV's Hello World\n",
    "\n",
    "To get started, you need to install the OpenCV library (version 4) on your computer. Numerous installation instructions are available on the official website:  \n",
    "+ [Installation](http://opencv.org/), under the Documentation - Tutorials or Quick Start section.\n",
    "\n",
    "You can also use the following commands:\n",
    "\n",
    "  `! pip install opencv-python`\n",
    "\n",
    "and \n",
    "\n",
    "   `! pip3 install opencv-contrib-python`\n",
    "\n",
    "Once the installation is complete, you should be able to compile and run a program that opens and displays an image. An image in OpenCV is represented as a matrix: the **Mat** structure. A detailed explanation of this data structure is available in the [tutorial here](https://docs.opencv.org/4.7.0/d6/d6d/tutorial_mat_the_basic_image_container.html). In Python, it is represented as a numpy array. If you are not familiar with numpy, you can follow this excellent [tutorial](http://cs231n.github.io/python-numpy-tutorial/).\n",
    "\n",
    "The code below demonstrates one way to load and display an image. Test it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QZ0TJjpyEo-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def loadImagebis(src):\n",
    "    img=cv2.imread(src,1)\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(rgb,interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "loadImagebis('./Images/oscar.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, images in OpenCV are in BGR format. It's important to keep this in mind when working with images. For example, refer to this short [post](https://medium.com/mlearning-ai/opencv-color-in-bgr-order-you-must-know-53470396d18c).  \n",
    "\n",
    "If you have never worked with images using OpenCV before, take the time to review the documentation for the functions used above, such as [`imread`](https://docs.opencv.org/4.x/d3/df2/tutorial_py_basic_ops.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PYrejt-yyEpD"
   },
   "source": [
    "## Exercise 2: Executing Some Simple Manipulations\n",
    "\n",
    "Creating a black image of size $3 \\times 3$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iT2penxMyEpF"
   },
   "outputs": [],
   "source": [
    "img = # to complete\n",
    "\n",
    "print(img)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(img.shape)\n",
    "print(img.size)\n",
    "print(img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEEIWKslyEpI"
   },
   "source": [
    "Loading and converting an image to HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ses0wrrcyEpK"
   },
   "outputs": [],
   "source": [
    "img=cv2.imread('./Images/oscar.jpg',1)\n",
    "print(img.shape, img.size,img.dtype)\n",
    "\n",
    "# to complete\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some manipulations on the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSV channels\n",
    "h = hsv[:,:,0]\n",
    "s = hsv[:,:,1]\n",
    "v = hsv[:,:,2]\n",
    "\n",
    "\n",
    "\n",
    "# Visualisation of the individual color channels\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,10))\n",
    "ax1.set_title('H channel')\n",
    "ax1.imshow(h, cmap='gray')\n",
    "ax2.set_title('S channel')\n",
    "ax2.imshow(s, cmap='gray')\n",
    "ax3.set_title('V channel')\n",
    "ax3.imshow(v, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to select the red part in the image using the hue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to select the red in the image using the hue channel\n",
    "lower_red_hue = \n",
    "upper_red_hue = \n",
    "\n",
    "# Define the masked area using inRange function\n",
    "\n",
    "# to complete\n",
    "\n",
    "# Convert image to monotone image \n",
    "# to complete\n",
    "\n",
    "\n",
    "\n",
    "# Mask and display the image\n",
    "# to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uck9qU8tyEpN"
   },
   "source": [
    "Retrieving the blue channel from an RGB image using `split`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZhQNIyxyEpO"
   },
   "outputs": [],
   "source": [
    "# to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXkkIgBXyEpS"
   },
   "source": [
    "Get pixel at position (100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bz0ZGhEeyEpT"
   },
   "outputs": [],
   "source": [
    "# to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ltihP5i0yEpb"
   },
   "source": [
    "## Exercise 3: First manipulations with OpenCV\n",
    "\n",
    "Write a function **loadImage(name, colorspace)** to open a grayscale or color image, return it and its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WT1AgYuGyEpc"
   },
   "outputs": [],
   "source": [
    "def loadImage(path, colorspace):\n",
    "    # TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90wOBS0KyEpf"
   },
   "source": [
    "Write a function **countPixels(I, k)** that returns the number of gray-level pixels $k$ in the image $I$. Be careful to work with a grayscale image. Do the same for a color image and a value $k$ equivalent to a triplet $(R,G,B)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0TlKYOEyEpg"
   },
   "outputs": [],
   "source": [
    "def compterPixels(l,k):\n",
    "    # TO COMPLETE\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tvQszPlWyEpj"
   },
   "source": [
    "Write a function **remplacePixels(I, k1,k2)** which saves, displays and returns the image corresponding to $I$ when the $k1$ values have been changed to $k2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7aTBwFIAyEpk"
   },
   "outputs": [],
   "source": [
    "def remplacePixels(I,k1,k2):\n",
    "    # TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "apW_hqwSyEpn"
   },
   "source": [
    "Write a function **inverseImage(I)** that returns the inverse image ($k'=255-k$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7R0fmksyEpo"
   },
   "outputs": [],
   "source": [
    "def inverseImage(I):\n",
    "    # TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VxA5O2T_yEpu"
   },
   "source": [
    "\n",
    "\n",
    "Write a function **histocompute(I)** that calculates, displays, and returns the histogram of the image *I*. For this, you can use the **cv2.calcHist** function from OpenCV or the **np.histogram** function from NumPy. A tutorial is available [here](http://docs.opencv.org/3.1.0/d1/db7/tutorial_py_histogram_begins.html). Make sure to thoroughly test the different parameters of the **cv2.calcHist** function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCcD0jpjyEpv"
   },
   "outputs": [],
   "source": [
    "def histocompute(I):\n",
    "    # TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXW57yi_yEpz"
   },
   "source": [
    "\n",
    "\n",
    "Write and test a function **threshold(I, s)** that returns a thresholded image *I* (pixels with values $> s$ are set to 255, and others are set to 0). You can use the **cv2.threshold** function. A tutorial is available [here](https://docs.opencv.org/4.7.0/d1/db7/tutorial_py_histogram_begins.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3H5Js82XyEpz"
   },
   "outputs": [],
   "source": [
    "def threshold(I,s):\n",
    "    # TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ybFZ5BdyEp3"
   },
   "source": [
    "## Exercise 4: A simple algorithm for skin detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpWfhJj9yEp4"
   },
   "source": [
    "\n",
    "\n",
    "The goal of this exercise is to design simple algorithms for detecting skin in images. This approach is based on several works from the literature, available on EDUNAO and in the `Articles_Documentation` folder, such as:\n",
    "\n",
    "+ A Survey on Pixel-Based Skin Color Detection Techniques, Vezhnevets V., Sazonov V., Andreeva A, IN PROC. GRAPHICON-2003, 2003.\n",
    "+ Statistical Color Models with Application to Skin Detection, Michael J. Jones, James M. Rehg, In Int. J. Comput. Vision 46, 1 (January 2002), 81-96.\n",
    "+ A survey of skin-color modeling and detection methods, P. Kakumanu, S. Makrogiannis, N. Bourbakis. In Pattern Recogn. 40, 3 (March 2007), 1106-1122.\n",
    "\n",
    "In particular, the following articles: *A survey of skin-color modeling and detection methods, P. Kakumanu, S. Makrogiannis, N. Bourbakis, IN Pattern Recognition, 2006*, and *A Survey on Pixel-Based Skin Color Detection Techniques, Vezhnevets V., Sazonov V., Andreeva A, IN PROC. GRAPHICON-2003, 2003* available in the `Articles_Documentation` folder, listing and describing the known approaches, will serve as the basis for developing your skin detection application. The general principle will involve using a database of *skin* examples and a database of *non-skin* examples, which will allow us to learn the skin color and build a model. As mentioned in the article, several questions arise:\n",
    "\n",
    "+ The choice of the color representation space, particularly to ensure good separation between skin and non-skin.\n",
    "+ How to construct the skin model (non-parametric or parametric).\n",
    "\n",
    "### Image Dataset\n",
    "For this lab, we will use a cleaned version of an existing dataset [the Pratheepan Dataset](http://web.fsktm.um.edu.my/~cschan/downloads_skin_dataset.html) available in the Data folder. All the images will be used to construct the skin model and the non-skin model. For the latter, additional images may be added to make the model more robust.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6Dj6LOcyEp5"
   },
   "source": [
    "\n",
    "\n",
    "### A Simple First Method\n",
    "\n",
    "The first method described in the article by Vezhnevets et al. consists of using a simple classification rule.\n",
    "\n",
    "A pixel with (RGB) components is classified as a skin pixel if:\n",
    "\n",
    "+ $R > 95$\n",
    "+ $G > 40$\n",
    "+ $B > 20$\n",
    "+ $\\max\\{R,G,B\\} - \\min\\{R,G,B\\} > 15$\n",
    "+ $|R-G| > 15$\n",
    "+ $R > G$\n",
    "+ $R > B$\n",
    "\n",
    "Implement this method and test it on a few images from the dataset as well as on skin and non-skin images not present in the dataset. Comment and discuss your results.\n",
    "\n",
    "Implementing this method will allow you to familiarize yourself with the main image manipulation functions (image traversal, pixel access, thresholding). By default, color images are in BGR, so the first component of a pixel corresponds to the blue channel rather than the red.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqOUVoHzyEp5"
   },
   "outputs": [],
   "source": [
    "def skindetectionsimple():\n",
    "    # TO COMPLETE\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97pCcjHPyEp9"
   },
   "source": [
    "\n",
    "\n",
    "### Non-Parametric Approach: Histogram and Skin Model\n",
    "\n",
    "Several color spaces can be used to detect skin regions in images. In this lab, one of the goals is to compare different types of color spaces. Specifically, you will compare RGB, HSV, and Lab spaces, but you may also test and compare others.\n",
    "\n",
    "#### Color Space Conversion\n",
    "\n",
    "The first task is to write a program that transforms an image from one color space to another. To do this, you will need to use the **cvtColor** function from OpenCV.\n",
    "+ [Tutorial](https://docs.opencv.org/4.7.0/df/d9d/tutorial_py_colorspaces.html)\n",
    "+ [Documentation](http://docs.opencv.org/4.7.0/d7/d1b/group__imgproc__misc.html#ga397ae87e1288a81d2363b61574eb8cab)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7eA1Kc4DyEp9"
   },
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llH5qkRByEqB"
   },
   "source": [
    "\n",
    "\n",
    "#### Construction of 2D Histograms\n",
    "\n",
    "Initially, we will work with the Lab color space. You will only use the *a* and *b* components (color axes) and not the *L* component (luminance axis). The task is to construct two **2D color histograms**, one for *skin* and one for *non-skin*. This is a 2-dimensional array (a and b for Lab, r and g for RGB, and h and s for HSV). For each dimension, you will reduce the scale of values from 256 to 32 (reducing the quantization), and for each cell in the array, you just need to count the number of pixels with the given (a,b) pair. All *skin* pixels from all images will go into the same histogram, and similarly for *non-skin* pixels. Each histogram will also be normalized by dividing each value by the total number of skin and non-skin pixels.\n",
    "\n",
    "For this, you can use the **calcHist** function from OpenCV. Unlike what was done earlier, you will need to:\n",
    "\n",
    "+ Construct a 2D histogram: [documentation](http://docs.opencv.org/4.7.0/dd/d0d/tutorial_py_2d_histogram.html)\n",
    "+ Use a mask to select the skin and non-skin regions (the mask being the ground truth image for the skin, and its complement for non-skin).\n",
    "+ Set the accumulate flag to true (since the histogram should be calculated over a set of images corresponding to each class).\n",
    "\n",
    "You need to construct two histograms for each color space chosen. These histograms will then be considered as a skin model and a non-skin model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KFeHVOjxyEqC"
   },
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kG_FpI0PyEqF"
   },
   "source": [
    "\n",
    "\n",
    "#### Skin Detection in Images from Histograms\n",
    "\n",
    "Several approaches can be used to detect skin in images (see the articles provided on Edunao). A simple approach is to calculate, for a pixel *p* in an image, its probability of being skin or non-skin based on its color *c* = (a,b) (note: only two components are used):\n",
    "\n",
    "+ $p(\\text{skin}|c) = p(c|\\text{skin}) = HistoSkin(a,b)$\n",
    "+ $p(\\neg \\text{skin}|c) = p(c|\\neg \\text{skin}) = HistoNonSkin(a,b)$\n",
    "\n",
    "The higher probability will determine whether the pixel is a skin pixel or not.\n",
    "\n",
    "Implement and test this method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9Jiz0CbyEqG"
   },
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hcds_cfEyEqJ"
   },
   "source": [
    "\n",
    "\n",
    "#### Skin Detection in Images: Bayes' Method\n",
    "\n",
    "This decision can be refined using Bayes' method:  \n",
    "$$p(\\text{skin}|c) = \\frac{p(c|\\text{skin}) p(\\text{skin})}{p(c|\\text{skin}) p(\\text{skin}) + p(c|\\neg \\text{skin}) p(\\neg \\text{skin})}$$  \n",
    "where $p(c|\\text{skin})$ and $p(c|\\neg \\text{skin})$ are given by the histograms, and $p(\\text{skin})$ and $p(\\neg \\text{skin})$ are the percentages of skin and non-skin pixels in your training dataset.  \n",
    "\n",
    "A classification rule can then be defined: classify a pixel as a skin pixel if $p(\\text{skin}|c) > \\Theta$, where $\\Theta$ is a threshold to be determined.  \n",
    "\n",
    "Implement and test this method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKV0gC1AyEqK"
   },
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1qJB5AgeyEqM"
   },
   "source": [
    "\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "Using the same image dataset as for your training, evaluate the percentage of skin pixels that you successfully detect (quantitative evaluation in terms of true positive rate (TP) and false positive rate (FP)). Does this seem satisfactory to you?\n",
    "\n",
    "Now evaluate your different approaches on another dataset for which ground truth is available but that was not used to build your skin models. Analyze your results. Specifically, you should include in your report examples of images where detection works well and others where it works less well, explaining why you think this is the case.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wB8bTGs1yEqN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_rAV3TxyEqQ"
   },
   "source": [
    "\n",
    "\n",
    "### Discussion\n",
    "\n",
    "How can the results you obtained be improved? Provide some ideas. What would need to be done to detect faces?  \n",
    "Feel free to suggest and test new ideas. Several variants that improve the results are possible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sA4VMpkdyEqR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LAB1_priseenmain_opencv.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
